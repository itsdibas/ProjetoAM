{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "## <center>Projeto Final</center>\n",
    "\n",
    "**Aluno**: Dival Siqueira Neto\n",
    "\n",
    "**RA**: 801289\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta célula, estamos importando todas as bibliotecas necessárias para o projeto:\n",
    "\n",
    "- `pandas`: Uma biblioteca para manipulação e análise de dados.\n",
    "- `sklearn.model_selection.train_test_split`: Uma função para dividir arrays ou matrizes em subconjuntos aleatórios de treino e teste.\n",
    "- `sklearn.feature_extraction.text.TfidfVectorizer`: Uma classe para converter uma coleção de documentos brutos em uma matriz de recursos TF-IDF.\n",
    "- `sklearn.naive_bayes.MultinomialNB`: Uma classe para realizar a classificação Naive Bayes multinomial.\n",
    "- `sklearn.metrics.roc_auc_score`: Uma função para calcular a área sob a curva ROC.\n",
    "- `re`: Uma biblioteca para trabalhar com expressões regulares.\n",
    "- `nltk`: Uma plataforma para trabalhar com linguagem humana.\n",
    "\n",
    "Também estamos importando duas funções de scripts personalizados:\n",
    "\n",
    "- `load_data` da `scripts.analise_exploratoria`: Uma função para carregar e pré-processar os dados.\n",
    "- `preprocess_text` da `scripts.preprocessamento`: Uma função para pré-processar o texto.\n",
    "\n",
    "Finalmente, estamos baixando os dados necessários do NLTK, se eles ainda não estiverem presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gc\n",
    "\n",
    "\n",
    "from scripts.preprocessamento import  load_data\n",
    "from scripts.analise_exploratoria import  make_predictions_and_save, plot_label_distribution, plot_fake_news_by_month, plot_word_frequency\n",
    "from scripts.experimentos import run_experiment_MultinomialNB, run_experiment_LogisticRegression, run_experiment_SVM, run_experiment_KNeighbors\n",
    "from scripts.analise_resultados import plot_metrics, plot_auc_roc\n",
    "\n",
    "# Baixar dados do NLTK, se não estiverem presentes\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pré-processamento\n",
    "\n",
    "Nesta seção, as funções da etapa de pré-processamento dos dados devem ser implementadas e aplicadas (se necessário)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código, estamos definindo uma lista de nomes de arquivos e um tamanho de lote, e então chamando a função `load_data` para carregar e pré-processar os dados desses arquivos.\n",
    "\n",
    "A lista `file_names` contém os nomes dos arquivos de dados que queremos carregar. Os nomes dos arquivos correspondem a diferentes meses de 2019 e 2020. Alguns nomes de arquivos estão comentados, o que significa que os dados desses arquivos não serão carregados.\n",
    "\n",
    "A variável `batch_size` é definida como 3000. Isso significa que a função `load_data` irá ler os arquivos de dados em lotes de 3000 linhas de cada vez. Isso é útil quando os arquivos de dados são muito grandes para serem lidos de uma só vez.\n",
    "\n",
    "Finalmente, chamamos a função `load_data` com `file_names` e `batch_size` como argumentos, e armazenamos o resultado na variável `news_data`. Isso irá carregar e pré-processar os dados dos arquivos especificados, e retornar um DataFrame do pandas contendo os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "   # \"news_data_01_Jan_2019\",\n",
    "   # \"news_data_02_Feb_2019\",\n",
    "   # \"news_data_03_Mar_2019\",\n",
    "   # \"news_data_04_Apr_2019\",\n",
    "   # \"news_data_05_May_2019\",\n",
    "   # \"news_data_06_Jun_2019\",\n",
    "   # \"news_data_07_Jul_2019\",\n",
    "    \"news_data_08_Aug_2019\",\n",
    "    \"news_data_09_Sep_2019\",\n",
    "    \"news_data_10_Oct_2019\",\n",
    "    \"news_data_11_Nov_2019\",\n",
    "    \"news_data_12_Dec_2019\", \n",
    "    \"news_data_13_Jan_2020\",\n",
    "    \"news_data_14_Feb_2020\",\n",
    "    \"news_data_15_Mar_2020\",\n",
    "    \"news_data_16_Apr_2020\",\n",
    "    \"news_data_17_May_2020\",\n",
    "    \"news_data_18_Jun_2020\",   \n",
    "]\n",
    "\n",
    "\n",
    "batch_size = 5000\n",
    "news_data = load_data(file_names, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código, estamos definindo uma lista de nomes de arquivos filtrados e, em seguida, chamando a função `load_data` para carregar e pré-processar os dados desses arquivos.\n",
    "\n",
    "A lista `filtered_news_data` contém os nomes dos arquivos de dados que queremos carregar. Esses nomes de arquivos correspondem a diferentes meses do segundo semestre de 2020.\n",
    "\n",
    "Em seguida, chamamos a função `load_data` com `filtered_news_data` e `batch_size` como argumentos, e armazenamos o resultado na variável `filtered_data`. Isso irá carregar e pré-processar os dados dos arquivos especificados, e retornar um DataFrame do pandas contendo os dados filtrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_news_data = [\n",
    "    \"news_data_19_Jul_2020\",\n",
    "    \"news_data_20_Aug_2020\",\n",
    "    \"news_data_21_Sep_2020\",\n",
    "    \"news_data_22_Oct_2020\",\n",
    "    \"news_data_23_Nov_2020\",\n",
    "    \"news_data_24_Dec_2020\"\n",
    "]\n",
    "filtered_data = load_data(filtered_news_data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trecho de código está realizando as seguintes operações:\n",
    "\n",
    "1. `file_names_low` é uma lista que contém o nome do arquivo que será carregado. Neste caso, o arquivo é \"news_data_12_Dec_2019\".\n",
    "\n",
    "2. `filtered_news_data_low` é um conjunto que contém o nome do arquivo que será carregado após a filtragem. Neste caso, o arquivo é \"news_data_24_Dec_2020\".\n",
    "\n",
    "3. `batch_size` é uma variável que define o tamanho do lote de dados a ser carregado de cada vez. Neste caso, o tamanho do lote é 5000.\n",
    "\n",
    "4. `news_data_low` é uma variável que armazena os dados carregados do arquivo especificado em `file_names_low` usando a função `load_data`.\n",
    "\n",
    "5. `filtered_data_low` é uma variável que armazena os dados carregados do arquivo especificado em `filtered_news_data_low` usando a função `load_data`.\n",
    "\n",
    "Em resumo, este código está carregando dados de dois arquivos diferentes em lotes de 5000 registros cada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_low = [\n",
    "    \"news_data_12_Dec_2019\", \n",
    "]\n",
    "\n",
    "filtered_news_data_low = {\n",
    "    \"news_data_24_Dec_2020\"\n",
    "}\n",
    "\n",
    "\n",
    "news_data_low = load_data(file_names_low, batch_size)\n",
    "filtered_data_low = load_data(filtered_news_data_low, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise exploratória\n",
    "\n",
    "Nesta seção, deve ser feita a leitura da base de dados e todas as análises necessárias para interpretar e analisar os dados, tais como:\n",
    "* Significado de cada atributo\n",
    "* Medidas descritivas\n",
    "* Gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neste trecho do código estão sendo plotados gráficos necessários para análise exploratória:\n",
    "\n",
    "`train_data` Carrega os dados de treinamento do arquivo 'train.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho do código estão sendo plotados gráficos necessários para análise exploratória:\n",
    "\n",
    "`plot_label_distribuction` Plota a distribuição das labels (categorias de notícias) nos dados\n",
    "\n",
    "`plot_fake_news_by_month` Plota a quantidade de notícias falsas por mês\n",
    "\n",
    " `plot_word_frequency` Plota as 10 notícias mais comuns tanto para notícias verdadeiras e falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_label_distribution(train_data)\n",
    "plot_fake_news_by_month(news_data, train_data)\n",
    "plot_word_frequency(news_data, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Experimento\n",
    "\n",
    "Nesta seção, o experimento deve ser conduzido, utilizando os protocolos experimentais padrões e testando diferentes modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código:\n",
    "\n",
    "1. `model1, best_params1, best_score1, auc_score1, accuracy1, f11, recall1, logloss1, tfidf_vectorizer1 = run_experiment_LogisticRegression(news_data, train_data)`: Esta linha executa a função `run_experiment_LogisticRegression` com os dados de notícias e de treinamento como argumentos. A função retorna várias saídas que são armazenadas nas variáveis `model1`, `best_params1`, `best_score1`, `auc_score1`, `accuracy1`, `f11`, `recall1`, `logloss1`, e `tfidf_vectorizer1`.\n",
    "\n",
    "2. `make_predictions_and_save(model1, tfidf_vectorizer1, filtered_data, \"submission1.csv\")`: Esta linha usa o modelo treinado e o vetorizador TF-IDF para fazer previsões nos dados filtrados. As previsões são então salvas em um arquivo CSV chamado \"submission1.csv\".\n",
    "\n",
    "3. `plot_metrics('LogisticRegression', best_params1, best_score1, auc_score1, accuracy1, f11, recall1, logloss1)`: Esta linha plota as métricas do modelo usando a função `plot_metrics`. As métricas incluem os melhores parâmetros, a melhor pontuação, a pontuação AUC, a precisão, o F1 score, o recall e a perda logarítmica.\n",
    "\n",
    "4. `del model1`: Esta linha exclui o modelo para liberar memória.\n",
    "\n",
    "5. `gc.collect()`: Esta linha chama a função `collect` do módulo `gc` (garbage collector) para liberar memória não utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, best_params1, best_score1, auc_score1, accuracy1, f11, recall1, logloss1, tfidf_vectorizer1 = run_experiment_LogisticRegression(news_data, train_data)\n",
    "#make_predictions_and_save(model1, tfidf_vectorizer1, filtered_data, \"submission1.csv\")\n",
    "\n",
    "del model1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código:\n",
    "\n",
    "1. `model2, best_params2, best_score2, auc_score2, accuracy2, f12, recall2, logloss2, tfidf_vectorizer2 = run_experiment_MultinomialNB(news_data, train_data)`: Esta linha executa a função `run_experiment_MultinomialNB` com os dados de notícias e de treinamento como argumentos. A função retorna várias saídas que são armazenadas nas variáveis `model2`, `best_params2`, `best_score2`, `auc_score2`, `accuracy2`, `f12`, `recall2`, `logloss2`, e `tfidf_vectorizer2`.\n",
    "\n",
    "2. `make_predictions_and_save(model2, tfidf_vectorizer2, filtered_data, \"submission2.csv\")`: Esta linha usa o modelo treinado e o vetorizador TF-IDF para fazer previsões nos dados filtrados. As previsões são então salvas em um arquivo CSV chamado \"submission2.csv\".\n",
    "\n",
    "3. `plot_metrics('MultinomialNB', best_params2, best_score2, auc_score2, accuracy2, f12, recall2, logloss2)`: Esta linha plota as métricas do modelo usando a função `plot_metrics`. As métricas incluem os melhores parâmetros, a melhor pontuação, a pontuação AUC, a precisão, o F1 score, o recall e a perda logarítmica.\n",
    "\n",
    "4. `del model2`: Esta linha exclui o modelo para liberar memória.\n",
    "\n",
    "5. `gc.collect()`: Esta linha chama a função `collect` do módulo `gc` (garbage collector) para liberar memória não utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2, best_params2, best_score2, auc_score2, accuracy2, f12, recall2, logloss2,  tfidf_vectorizer2 = run_experiment_MultinomialNB(news_data, train_data)\n",
    "#make_predictions_and_save(model2, tfidf_vectorizer2, filtered_data, \"submission2.csv\")\n",
    "\n",
    "\n",
    "del model2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código:\n",
    "\n",
    "1. `model3, best_params3, best_score3, auc_score3, accuracy3, f13, recall3, logloss3,  tfidf_vectorizer3 = run_experiment_SVM(news_data, train_data)`: Esta linha está executando a função `run_experiment_SVM` com os dados de notícias e de treinamento como argumentos. A função retorna nove valores que são atribuídos às variáveis `model3`, `best_params3`, `best_score3`, `auc_score3`, `accuracy3`, `f13`, `recall3`, `logloss3` e `tfidf_vectorizer3`.\n",
    "\n",
    "2. `make_predictions_and_save(model3, tfidf_vectorizer3, filtered_data, \"submission2.csv\")`: Esta linha está chamando a função `make_predictions_and_save` para fazer previsões usando o modelo e o vetorizador TF-IDF treinados, e salvar as previsões no arquivo \"submission2.csv\".\n",
    "\n",
    "3. `plot_metrics('SVM', best_params3, best_score3, auc_score3, accuracy3, f13, recall3, logloss3)`: Esta linha está chamando a função `plot_metrics` para plotar as métricas do modelo treinado.\n",
    "\n",
    "4. `del model3`: Esta linha está deletando a variável `model3` para liberar memória.\n",
    "\n",
    "5. `gc.collect()`: Esta linha está chamando a função `gc.collect()` para liberar memória não utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3, best_params3, best_score3, auc_score3, accuracy3, f13, recall3, logloss3,  tfidf_vectorizer3 = run_experiment_SVM(news_data_low, train_data)\n",
    "#make_predictions_and_save(model3, tfidf_vectorizer3, filtered_data_low, \"submission3.csv\")\n",
    "\n",
    "\n",
    "del model3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código:\n",
    "\n",
    "1. `model4, best_params4, best_score4, auc_score4, accuracy4, f14, recall4, logloss4, tfidf_vectorizer4 = run_experiment_KNeighbors(news_data, train_data)`: Esta linha executa a função `run_experiment_KNeighbors` com os dados de notícias e de treinamento como argumentos. A função retorna vários valores que são armazenados nas variáveis `model4`, `best_params4`, `best_score4`, `auc_score4`, `accuracy4`, `f14`, `recall4`, `logloss4` e `tfidf_vectorizer4`.\n",
    "\n",
    "2. `make_predictions_and_save(model4, tfidf_vectorizer3, filtered_data, \"submission2.csv\")`: Esta linha usa a função `make_predictions_and_save` para fazer previsões com o modelo e o vetorizador TF-IDF, e salva as previsões no arquivo \"submission2.csv\".\n",
    "\n",
    "3. `plot_metrics('KNeighbors', best_params4, best_score4, auc_score4, accuracy4, f14, recall4, logloss4)`: Esta linha chama a função `plot_metrics` para plotar as métricas do modelo KNeighbors.\n",
    "\n",
    "4. `del model4`: Esta linha exclui o modelo para liberar memória.\n",
    "\n",
    "5. `gc.collect()`: Esta linha chama a função `collect` do módulo `gc` (garbage collector) para liberar memória não utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4, best_params4, best_score4, auc_score4, accuracy4, f14, recall4, logloss4,  tfidf_vectorizer4 = run_experiment_KNeighbors(news_data_low, train_data)\n",
    "#make_predictions_and_save(model4, tfidf_vectorizer4, filtered_data_low, \"submission4.csv\")\n",
    "\n",
    "del model4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise dos Resultados\n",
    "\n",
    "Nesta seção, os resultados devem ser exibidos através de tabelas e gráficos, comparados e profundamente analisados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trecho de código está chamando a função `plot_metrics` para cada um dos quatro modelos de classificação: Regressão Logística, Multinomial Naive Bayes, Máquinas de Vetores de Suporte (SVM) e K Vizinhos Mais Próximos (KNeighbors).\n",
    "\n",
    "A função `plot_metrics` provavelmente recebe o nome do modelo e várias métricas de desempenho como argumentos e gera um gráfico ou vários gráficos para visualizar essas métricas.\n",
    "\n",
    "Aqui está o que cada argumento provavelmente representa:\n",
    "\n",
    "1. 'LogisticRegression', 'MultinomialNB', 'SVM', 'KNeighbors': Estes são os nomes dos modelos.\n",
    "2. `best_params1`, `best_params2`, `best_params3`, `best_params4`: Estes são os melhores parâmetros encontrados para cada modelo.\n",
    "3. `best_score1`, `best_score2`, `best_score3`, `best_score4`: Estes são os melhores scores obtidos por cada modelo.\n",
    "4. `auc_score1`, `auc_score2`, `auc_score3`, `auc_score4`: Estes são os scores AUC-ROC obtidos por cada modelo.\n",
    "5. `accuracy1`, `accuracy2`, `accuracy3`, `accuracy4`: Estas são as acurácias obtidas por cada modelo.\n",
    "6. `f11`, `f12`, `f13`, `f14`: Estes são os scores F1 obtidos por cada modelo.\n",
    "7. `recall1`, `recall2`, `recall3`, `recall4`: Estes são os recalls obtidos por cada modelo.\n",
    "8. `logloss1`, `logloss2`, `logloss3`, `logloss4`: Estes são os log losses obtidos por cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics('LogisticRegression', best_params1, best_score1, auc_score1, accuracy1, f11, recall1, logloss1)\n",
    "plot_metrics('MultinomialNB', best_params2, best_score2, auc_score2, accuracy2, f12, recall2, logloss2)\n",
    "plot_metrics('SVM', best_params3, best_score3, auc_score3, accuracy3, f13, recall3, logloss3)\n",
    "plot_metrics('KNeighbors', best_params4, best_score4, auc_score4, accuracy4, f14, recall4, logloss4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Lista de nomes dos modelos:\n",
    "\n",
    "`models` = ['LogisticRegression', 'MultinomialNB', 'SVM', 'KNeighbors'] ``\n",
    "\n",
    "Lista de scores AUC-ROC para cada modelo:\n",
    "\n",
    "`auc_scores` = [auc_score1, auc_score2, auc_score3, auc_score4]\n",
    "\n",
    " Chama a função plot_auc_roc com os nomes dos modelos e os scores AUC-ROC:\n",
    " \n",
    "`plot_auc_roc`(models, auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de nomes dos modelos\n",
    "models = ['LogisticRegression', 'MultinomialNB', 'SVM', 'KNeighbors']\n",
    "# Lista de scores AUC-ROC para cada modelo\n",
    "auc_scores = [auc_score1, auc_score2, auc_score3, auc_score4]\n",
    "\n",
    "# Chama a função plot_auc_roc com os nomes dos modelos e os scores AUC-ROC\n",
    "plot_auc_roc(models, auc_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
